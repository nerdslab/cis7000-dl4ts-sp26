{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBkwWhCLz4uO"
      },
      "source": [
        "# Time Series: Introduction, Generalization, and Domain Shift\n",
        "\n",
        "**Course:** Deep Learning for Time Series  \n",
        "**Instructor:** Eva Dyer  \n",
        "\n",
        "**Goals:**  \n",
        "- Understand what makes time series special\n",
        "- Define generalization in time series\n",
        "- Introduce the concepts of *domain* and *domain shift*\n",
        "- Formalize different types of distribution shift (covariate, label, concept shift)\n",
        "- Build time series examples of each shift type\n",
        "- Develop a first-pass taxonomy of adaptation methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMs4Ra9jz4uP"
      },
      "outputs": [],
      "source": [
        "# Run this to initialize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1x6Df9Az4uP"
      },
      "source": [
        "## 1. What is a time series?\n",
        "\n",
        "- A sequence of observations indexed by time: $(x_1, x_2, \\ldots, x_T)$, where $x_t \\in \\mathbb{R}^d$.\n",
        "  - If $x_t$ are regularly sampled, we call it a *regular time series*. This is the most common case. Examples:\n",
        "    - Physiological signals (EEG, ECG, EMG)\n",
        "    - Wearables (IMU, accelerometers, step counts)\n",
        "    - Financial series (prices, volumes)\n",
        "    - Environmental data (weather, air quality, traffic)\n",
        "  - Otherwise, we call it an *irregular time series*. Examples:\n",
        "    - Event sequences (anomalies, natural disasters)\n",
        "    - Neural activity (spike trains)\n",
        "    - Longitudinal studies (health records)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbhK0I_Oyx19"
      },
      "source": [
        "- Tasks:\n",
        "  - **Forecasting:** predict future values\n",
        "  - **Classification:** assign labels to a sequence (e.g., arrhythmia vs normal)\n",
        "  - **Segmentation:** detect events or state transitions in time\n",
        "  - **Anomaly detection:** identify unusual behaviours\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/nerdslab/cis7000-dl4ts-sp26/refs/heads/notebooks/figures/ts-tasks.png\" width=\"800\">\n",
        "</center>\n",
        "\n",
        "- Another useful characterization of tasks is whether they map the time series to a single label (sequence-level prediction) or another sequence (dense / frame-level prediction):\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/nerdslab/cis7000-dl4ts-sp26/refs/heads/notebooks/figures/seq-frame-level.png\" width=\"600\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHekuMf4y01t"
      },
      "source": [
        "### 1.1 Autoregressive time series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LesBrcjYy8yI"
      },
      "source": [
        "A basic model for regular time series is the autoregressive $AR(p)$ model:\n",
        "$$\n",
        "x_t = \\sum_{i=1}^p \\beta_i x_{t-i} + ɛ_t\n",
        "$$\n",
        "This model assumes that the time series was generated as a process where every time point depends linearly on the sliding window of $p$ observations before it (plus some noise)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS4crL4Vz4uP"
      },
      "outputs": [],
      "source": [
        "# Helper function: Generate AR(1) time series\n",
        "def generate_ar1(T=200, phi=0.5, sigma=1.0):\n",
        "    \"\"\"Generate an AR(1) time series: x[t] = phi * x[t-1] + noise\"\"\"\n",
        "    x = np.zeros(T)\n",
        "    epsilon = np.random.normal(0, sigma, T)\n",
        "    for t in range(1, T):\n",
        "        x[t] = phi * x[t-1] + epsilon[t]\n",
        "    return x\n",
        "\n",
        "x = generate_ar1()\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.plot(x)\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.title(\"Example AR(1) Time Series\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCeJohSDz4uQ"
      },
      "source": [
        "## 2. Generalization in time series\n",
        "\n",
        "In standard i.i.d. ML, we talk about train/test splits over *samples*.\n",
        "\n",
        "For time series, we have at least three axes:\n",
        "\n",
        "1. **Time:** train on early times, test on later times  \n",
        "2. **Entities:** train on some patients/devices, test on new ones  \n",
        "3. **Environments:** train in one context (hospital A), test in another (hospital B)\n",
        "\n",
        "**Key Questions:**\n",
        "- What does it mean to \"generalize\" if the data distribution drifts over time?\n",
        "- How do we design splits that reflect realistic deployment?\n",
        "- What happens when training and test data come from different distributions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w-Ruv9_AvUX"
      },
      "source": [
        "### 2.1 Example: Two patients, each with AR(1) data with different means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MXfAz2Iz4uQ"
      },
      "outputs": [],
      "source": [
        "# Simple toy: two patients, each with AR(1) data with different means\n",
        "def patient_series(T=200, mean=0.0):\n",
        "    raw_signal = generate_ar1(T)\n",
        "    #    \"An event is anything > 1 std dev in the underlying signal\"\n",
        "    labels = (raw_signal > 1.0).astype(int)\n",
        "    observed_data = raw_signal + mean\n",
        "    return observed_data, labels\n",
        "\n",
        "T = 200\n",
        "p1, y1 = patient_series(T, mean=0.0)\n",
        "p2, y2 = patient_series(T, mean=5.0)\n",
        "\n",
        "plt.figure(figsize=(8,3))\n",
        "plt.plot(p1, label=\"Patient 1\")\n",
        "plt.plot(p2, label=\"Patient 2\")\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.title(\"Toy data: two patients with different means\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf183RUoz4uQ"
      },
      "source": [
        "### Example: naive vs realistic evaluation\n",
        "\n",
        "- **Naive split:** randomly shuffle all time points from both patients\n",
        "  - Training and test sets have mixed patient identities and time periods\n",
        "  - Overly optimistic performance\n",
        "\n",
        "- **More realistic:**\n",
        "  - Train on *Patient 1* + early part of *Patient 2*\n",
        "  - Test on later part of *Patient 2* or a completely new patient\n",
        "\n",
        "This demonstrates the challenge of **domain shift** — when training and test data come from different distributions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c1STcXuz4uQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Naive Random Split\n",
        "# -----------------------------\n",
        "X_all = np.concatenate([p1[:, None], p2[:, None]])\n",
        "y_all = np.concatenate([y1, y2])\n",
        "\n",
        "# Shuffle everything together\n",
        "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(\n",
        "    X_all, y_all, test_size=0.5, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "# Fit logistic regression classifier on the raw inputs\n",
        "clf_naive = LogisticRegression(random_state=42).fit(X_train_n, y_train_n)\n",
        "print(f\"Naive Split Accuracy: {clf_naive.score(X_test_n, y_test_n):.2%}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Realistic Patient-level Split\n",
        "# -----------------------------\n",
        "# Train ONLY on Patient 1\n",
        "X_train_patient = p1[:, None]\n",
        "y_train_patient = y1\n",
        "\n",
        "# Test ONLY on Patient 2\n",
        "X_test_patient = p2[:, None]\n",
        "y_test_patient = y2\n",
        "\n",
        "clf_patient = LogisticRegression(random_state=42).fit(X_train_patient, y_train_patient)\n",
        "print(f\"\\nPatient wise split Accuracy: {clf_patient.score(X_test_patient, y_test_patient):.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcsjLuwkz4uQ"
      },
      "source": [
        "**Note:** It is crucial to design your train/test splits based on how the model will be deployed. If you plan to use the model on new users, you must use a Subject-Wise split to expose distribution shifts. A easy fix would be here to standardize the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raX3abmhz4uQ"
      },
      "outputs": [],
      "source": [
        "# Scale Patient 1 (Train)\n",
        "scaler_p1 = StandardScaler()\n",
        "X_train_scaled = scaler_p1.fit_transform(p1.reshape(-1, 1))\n",
        "\n",
        "# Scale Patient 2 (Test)\n",
        "scaler_p2 = StandardScaler()\n",
        "X_test_scaled = scaler_p2.fit_transform(p2.reshape(-1, 1))\n",
        "\n",
        "clf_fixed = LogisticRegression(random_state=42)\n",
        "clf_fixed.fit(X_train_scaled, y_train_patient)\n",
        "\n",
        "acc_fixed = clf_fixed.score(X_test_scaled, y_test_patient)\n",
        "print(f\"Patient wise split Accuracy: {acc_fixed:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFVSY6Nnz4uQ"
      },
      "source": [
        "## 3. Domains and Domain Shift\n",
        "\n",
        "### 3.1 Basic Definitions\n",
        "\n",
        "- **Domain:** a distribution over input–label pairs $(X, Y)$, e.g.\n",
        "  - Hospital A vs Hospital B\n",
        "  - Device A vs Device B\n",
        "  - Patient 1 vs Patient 2\n",
        "  - Pre- vs post-covid\n",
        "  - Different time periods\n",
        "\n",
        "- **Domain shift:** training and test data come from different domains  \n",
        "  (different marginals or conditionals)\n",
        "  \n",
        "  Formally, if $p_{\\text{source}}(x, y) \\neq p_{\\text{target}}(x, y)$, we have domain shift.\n",
        "\n",
        "- **Domain adaptation:** using labeled data from a *source* domain to perform\n",
        "  well on a (possibly unlabeled) *target* domain.\n",
        "\n",
        "- **Time series domain adaptation:** adapting across people, devices, and time periods.\n",
        "\n",
        "The example above showed a domain shift between Patient 1 and Patient 2. But domain shift can manifest in different ways, which we'll explore next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iea4edOnVNne"
      },
      "source": [
        "## 4. Types of Distribution Shift\n",
        "\n",
        "To understand how these shifts arise, recall that the joint distribution $p(x, y)$ can be decomposed in two ways using the chain rule of probability:\n",
        "\n",
        "1. $p(x, y) = p(y|x)p(x)$\n",
        "2. $p(x, y) = p(x|y)p(y)$\n",
        "\n",
        "We get different types of distribution shifts by varying one part of these equations (letting it change between training and testing).\n",
        "\n",
        "Let $p_{\\text{train}}(x, y)$ and $p_{\\text{test}}(x, y)$ be the joint distributions.\n",
        "\n",
        "There are three main types of distribution shift:\n",
        "\n",
        "1. **Covariate shift:** $p_{\\text{train}}(x) \\neq p_{\\text{test}}(x)$, but $p(y|x)$ stays the same.\n",
        "- Example: same labeling protocol, but sensor calibration changes\n",
        "\n",
        "- Example: training on photos of dogs and cats, but testing on drawings of dogs and cats\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nerdslab/cis7000-dl4ts-sp26/refs/heads/notebooks/figures/covariate-dogscats.png\" width=\"400\">\n",
        "\n",
        "2. **Label shift:** $p_{\\text{train}}(y) \\neq p_{\\text{test}}(y)$, but $p(x|y)$ stays the same.\n",
        "- Example: class prevalence changes (e.g., more positive cases when testing), but the signal characteristics for each class stay the same\n",
        "\n",
        "- Example: classifying breeds of dogs by image, training on images from a dog show, but deployed on a dataset of pets\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nerdslab/cis7000-dl4ts-sp26/refs/heads/notebooks/figures/label-dogs.png\" width=\"400\">\n",
        "\n",
        "3. **Concept shift (Concept Gap):** $p_{\\text{train}}(y|x) \\neq p_{\\text{test}}(y|x)$.\n",
        "- Example: different hospitals use different diagnostic thresholds\n",
        "\n",
        "- Example: training a binary classifier to detect planets in 2005 (one year before Pluto was declared a dwarf planet!), but deploying in 2007\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nerdslab/cis7000-dl4ts-sp26/refs/heads/notebooks/figures/concept-pluto.png\" width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlml8HwPVNne"
      },
      "source": [
        "## 5. Examples of Distribution Shifts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hprcsYeHz4uQ"
      },
      "source": [
        "### 5.1 Concept Shift\n",
        "\n",
        "**Concept shift** (also called **concept drift** or **concept gap**) occurs when the mapping from inputs to labels ($Y|X$) changes between domains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOZDKBPZz4uQ"
      },
      "source": [
        "To isolate this effect, we will keep the input distribution ($X$) **identical** for both Train and Test. The only thing that changes is the **rule** used to decide the label ($Y|X$).\n",
        "\n",
        "* **Hospital A (Train):** Any value $> 3$ is treated as a Case (Class 1).\n",
        "* **Hospital B (Test):** Only values $> 7$ are treated as a Case (Class 1).\n",
        "\n",
        "Patients with sensor readings between **3 and 7** are labeled **Positive (1)** in the training data, but **Negative (0)** in the test data. This creates a \"Concept Gap\" where the model's learned rules directly contradict the new environment's reality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQoGnjqbz4uQ"
      },
      "outputs": [],
      "source": [
        "n_samples = 200\n",
        "\n",
        "# 1. Generate Input Features (X)\n",
        "# Both domains have the exact SAME input distribution (0 to 10)\n",
        "# This ensures the failure isn't due to \"Covariate Shift\"\n",
        "X_train = np.random.uniform(0, 10, n_samples).reshape(-1, 1)\n",
        "X_test  = np.random.uniform(0, 10, n_samples).reshape(-1, 1)\n",
        "\n",
        "# 2. Define the Concept Shift (Different Labeling Rules)\n",
        "# Train Domain: Threshold > 3\n",
        "y_train = (X_train > 3).astype(int).ravel()\n",
        "\n",
        "# Test Domain: Threshold > 7\n",
        "y_test = (X_test > 7).astype(int).ravel()\n",
        "\n",
        "\n",
        "# 4. Visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Training Data\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.scatter(X_train, y_train, c=y_train, cmap='coolwarm', edgecolors='k', alpha=0.6)\n",
        "plt.axvline(3, color='green', linestyle='--', linewidth=2, label='Learned Boundary (x > 3)')\n",
        "plt.title(\"Training Domain (Hospital A): Threshold > 3\")\n",
        "plt.yticks([0, 1], ['Normal (0)', 'Case (1)'])\n",
        "plt.legend(loc='center right')\n",
        "\n",
        "# Test Data\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.scatter(X_test, y_test, c=y_test, cmap='coolwarm', edgecolors='k', alpha=0.6)\n",
        "\n",
        "plt.axvline(3, color='green', linestyle='--', linewidth=2, label='Model Boundary (From Train)')\n",
        "plt.axvline(7, color='black', linestyle='-', linewidth=2, label='True Test Boundary (x > 7)')\n",
        "\n",
        "plt.axvspan(3, 7, color='red', alpha=0.2, label='Concept Gap (Model Error)')\n",
        "\n",
        "plt.title(\"Test Domain (Hospital B): Threshold > 7\")\n",
        "plt.xlabel(\"Sensor Value\")\n",
        "plt.yticks([0, 1], ['Normal (0)', 'Case (1)'])\n",
        "plt.legend(loc='center right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alCC37w7XzY_"
      },
      "source": [
        "# Exercise: Simulating Distribution Shifts\n",
        "\n",
        "Generate synthetic data to visualize Label Shift and Covariate Shift.\n",
        "\n",
        "How can we adapt a model to each of these distribution shifts?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JHXHhT5VNne"
      },
      "source": [
        "### 5.2 Label Shift\n",
        "\n",
        "**Label shift** occurs when the distribution of the class labels ($Y$) changes, while the relationship between the class and its features ($P(X|Y)$) remains constant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18mZrE8vVNne"
      },
      "source": [
        "To isolate this effect, we will keep the feature generation logic ($P(X|Y)$) **identical** for both Train and Test. The only thing that changes is the **proportion** of labels ($Y$).\n",
        "\n",
        "* **Hospital A (Train):** A balanced scenario where **50%** of patients are Cases (e.g., during a pandemic peak).\n",
        "* **Hospital B (Test):** A low-prevalence scenario where only **10%** of patients are Cases (e.g., normal operations).\n",
        "\n",
        "The underlying concept haven't changed—a \"Case\" looks exactly the same in both hospitals. However, a model trained on Hospital A learns a strong **prior bias** that the disease is common. When applied to Hospital B, this model will likely over-predict the positive class (producing excessive False Positives) simply because it expects the disease to be far more frequent than it actually is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8jqK_3VVNnf"
      },
      "outputs": [],
      "source": [
        "n_samples = 500\n",
        "\n",
        "# 1. Define the Fixed Mechanism P(X|Y)\n",
        "def generate_patient_symptoms(labels):\n",
        "    readings = []\n",
        "    for y in labels:\n",
        "        if y == 0:\n",
        "            # Normal: Low sensor readings (mean=3)\n",
        "            # TODO implement: sample from Gaussian\n",
        "        else:\n",
        "            # Case: High sensor readings (mean=8)\n",
        "            # This \"symptom\" definition is identical for both Hospital A and B\n",
        "            # TODO implement: sample from Gaussian\n",
        "    return np.array(readings).reshape(-1, 1)\n",
        "\n",
        "# 2. Generate Data with LABEL SHIFT\n",
        "# Hospital A (Train): \"Balanced scenario where 50% of patients are Cases\"\n",
        "y_train = # TODO implement: 50% Normal, 50% Case\n",
        "X_train = # TODO implement\n",
        "\n",
        "# Hospital B (Test): \"Low-prevalence scenario where only 10% of patients are Cases\"\n",
        "y_test = # TODO implement: 90% Normal, 10% Case\n",
        "X_test = # TODO implement\n",
        "\n",
        "# 3. Visualization\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Hospital A Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(X_train[y_train==0], bins=20, alpha=0.6, color='blue', label='Normal (0)')\n",
        "plt.hist(X_train[y_train==1], bins=20, alpha=0.6, color='red', label='Case (1)')\n",
        "plt.title(f\"Hospital A (Train)\\nBalanced: 50% Cases\")\n",
        "plt.xlabel(\"Sensor Value\")\n",
        "plt.ylabel(\"Patient Count\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Hospital B Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(X_test[y_test==0], bins=20, alpha=0.6, color='blue', label='Normal (0)')\n",
        "plt.hist(X_test[y_test==1], bins=20, alpha=0.6, color='red', label='Case (1)')\n",
        "plt.title(f\"Hospital B (Test)\\nLow Prevalence: 10% Cases\")\n",
        "plt.xlabel(\"Sensor Value\")\n",
        "plt.ylabel(\"Patient Count\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(\"Label Shift: Symptoms P(X|Y) stay fixed, P(Y) changes\", y=1.02, fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiT1pIL5VNnf"
      },
      "source": [
        "**Q: How can we fix this kind of shift?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie2KC1HxVNnf"
      },
      "source": [
        "**ANS**: TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJSQHpeNVNnf"
      },
      "source": [
        "### 4.3 Covariate Shift\n",
        "\n",
        "**Covariate shift** occurs when the input distribution $p(x)$ changes but the label mapping $p(y|x)$ remains the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eutE3AlOVNnf"
      },
      "source": [
        "To isolate this, we will change the **Input Distribution** ($X$) but keep the **Labeling Rule** ($Y|X$) identical.\n",
        "\n",
        "* **Sensor A (Train):** A \"Failure\" (Class 1) creates a **mild** signal spike (centered at 2.0).\n",
        "* **Sensor B (Test):** A \"Failure\" (Class 1) creates a **severe** signal spike (centered at 6.0).\n",
        "\n",
        "The \"Normal\" state (Class 0) looks the same in both cases. However, the model learns to identify failures by looking for \"mild\" spikes. When tested on Sensor B, the failures look completely different (much higher), and the model might treat them as outliers or a different class entirely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLIG1kaWVNnf"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "T_cond = 200\n",
        "\n",
        "# 1. Define Labels (Y)\n",
        "# The label distribution is fixed (random 0s and 1s)\n",
        "y_cond = # TODO implement\n",
        "\n",
        "# 2. Define Covariate Shift (Sensor Drift)\n",
        "# Train: Values are ~0 and ~1\n",
        "# P(x|y) -> x = y + noise\n",
        "x_train_cond = # TODO implement\n",
        "\n",
        "# Test: Values are shifted by +1.5 -> (~1.5 and ~2.5)\n",
        "# P(x|y) changes -> x = y + 1.5 + noise\n",
        "x_test_cond = # TODO implement\n",
        "\n",
        "# 3. Visualization\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot Train Data\n",
        "plt.scatter(range(T_cond), x_train_cond, c=y_cond, cmap='coolwarm', marker='o', alpha=0.6, label=\"Train Data\")\n",
        "\n",
        "# Plot Test Data\n",
        "plt.scatter(range(T_cond, 2*T_cond), x_test_cond, c=y_cond, cmap='coolwarm', marker='x', alpha=0.6, label=\"Test Data\")\n",
        "\n",
        "# The Decision Boundary (Learned from Train)\n",
        "# Model learns that anything > 0.5 is Class 1\n",
        "plt.axhline(y=0.5, color='green', linestyle='--', linewidth=2, label=r'$\\mathbf{Learned}$ Boundary (x > 0.5)')\n",
        "\n",
        "# Highlight the Error Zone\n",
        "plt.axhspan(0.5, 3.0, color='red', alpha=0.1, label='Model predicts \"Class 1\" here')\n",
        "\n",
        "plt.title(\"Covariate Shift\")\n",
        "plt.xlabel(\"Sample Index\")\n",
        "plt.ylabel(\"Signal Value\")\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA7h9rkQYxFu"
      },
      "source": [
        "**Q: How can we fix this kind of shift?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DqjSjeJYyiU"
      },
      "source": [
        "**ANS**: TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZvWar4mz4uR"
      },
      "source": [
        "## 6. Adaptation Settings and Methods\n",
        "\n",
        "When faced with domain shift, we have several adaptation strategies. These can be categorized along multiple axes:\n",
        "\n",
        "### Axis 1: Target Labels?\n",
        "- **Labeled target:** supervised / semi-supervised domain adaptation\n",
        "  - We have some labeled examples from the target domain\n",
        "- **Unlabeled target:** *unsupervised domain adaptation* (UDA)\n",
        "  - We only have unlabeled examples from the target domain\n",
        "  - Most common and challenging setting\n",
        "\n",
        "### Axis 2: Retraining Allowed?\n",
        "- **Full retraining / joint training:** train on source + target data together\n",
        "- **Parameter-efficient tuning:** adapters, LoRA, fine-tuning only some layers\n",
        "- **Test-time adaptation (TTA):** update model using test stream only\n",
        "  - No access to source data during deployment\n",
        "  - Must adapt on-the-fly\n",
        "\n",
        "### Axis 3: Multi-domain Structure (for time series)\n",
        "- **Single source vs multi-source:** adapt from one or many source domains (patients/devices)\n",
        "- **Single target vs continual / streaming targets:**\n",
        "  - Adapt to one target domain, or\n",
        "  - Continuously adapt as new domains arrive over time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWsE4mPoz4uR"
      },
      "source": [
        "## 7. Summary and Key Takeaways\n",
        "\n",
        "1. **Time series generalization** is challenging due to multiple axes: time, entities, and environments.\n",
        "\n",
        "2. **Domain shift** occurs when training and test distributions differ:\n",
        "   - **Covariate shift:** $p(x)$ changes, $p(y|x)$ stays the same\n",
        "   - **Label shift:** $p(y)$ changes, $p(x|y)$ stays the same  \n",
        "   - **Concept shift (concept gap):** $p(y|x)$ changes — **typically the most challenging!**\n",
        "\n",
        "3. **Realistic evaluation** requires splitting data respecting domain boundaries (e.g., leave-one-patient-out), not random shuffling.\n",
        "\n",
        "4. **Domain adaptation** strategies depend on:\n",
        "   - Whether target labels are available\n",
        "   - Whether retraining is allowed\n",
        "   - Single vs. multi-domain structure\n",
        "\n",
        "5. **Concept gap** is particularly problematic because the input-label relationship itself changes. Simply correcting for input distribution differences is not enough."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
